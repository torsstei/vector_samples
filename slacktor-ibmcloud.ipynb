{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a41b16-b280-47bd-9996-597e22819d25",
   "metadata": {},
   "source": [
    "# A simple Vector Pipeline for a RAG-based AI using Slack as Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01b8a5-a3d9-4838-b7a6-8ecb3ff8437c",
   "metadata": {},
   "source": [
    "This notebook has three sections:\n",
    "1. Scraping the conversations from a slack channel\n",
    "2. Preparing and chunking the scraped conversations\n",
    "3. Configure an embedding model to use for computating the vector embeddings for the conversations\n",
    "4. Uploading the vector embeddings to a vector database\n",
    "5. Prompting an LLM with a retrieval augmentation using the vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bcbdb4-08b9-4264-8b87-65d8dc33fe3b",
   "metadata": {},
   "source": [
    "## Scraping Slack Conversations using Slack API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8e23b0d-9c06-4746-9768-1a1da14cd88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install slack_sdk | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce18314-4f6a-40c9-b2fd-c6c30188bc61",
   "metadata": {},
   "source": [
    "Create a little helper class to simplify the usage of Slack SDK for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99652e2-b181-49e5-8fe8-800d5ddfd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import getpass\n",
    "import time\n",
    "import os\n",
    "from slack_sdk import WebClient\n",
    "\n",
    "class SlackHelper:\n",
    "\n",
    "    def __init__(self, token: str):\n",
    "        self._username_cache = dict()\n",
    "        self._slack_client = WebClient(token)\n",
    "        self._slack_client.api_test()\n",
    "\n",
    "    def get_messages_from_channel(self, channel):\n",
    "        messages = self._slack_client.conversations_history(channel=channel)[\"messages\"]\n",
    "        conversation = \"\"\n",
    "        for message in reversed(messages):\n",
    "            message_ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(float(message[\"ts\"])))\n",
    "            conversation = conversation + \"(\" + message_ts + \", user=\" + self.get_user_name(message[\"user\"]) + \"): \" + message[\"text\"] + \"\\n\"\n",
    "            if \"thread_ts\" in message:\n",
    "                replies = self._slack_client.conversations_replies(channel=channel, ts=message[\"thread_ts\"])[\"messages\"]\n",
    "                for reply in replies[1:]:\n",
    "                    reply_ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(float(message[\"ts\"])))\n",
    "                    conversation = conversation + \"      (\" + reply_ts + \", user=\" + self.get_user_name(reply[\"user\"]) + \"): \" + reply[\"text\"]  + \"\\n\"\n",
    "        return conversation    \n",
    "\n",
    "    def get_user_name(self, user):\n",
    "        if user not in self._username_cache:\n",
    "            self._username_cache[user] = self._slack_client.users_info(user=user)[\"user\"][\"real_name\"]\n",
    "        return self._username_cache[user]\n",
    "\n",
    "    def get_conversations_info(self, channel):\n",
    "        response = self._slack_client.conversations_info(channel=channel, include_num_members=1)\n",
    "        return response[\"channel\"]\n",
    "\n",
    "    def list_channels(self):\n",
    "        response = self._slack_client.conversations_list(types=\"public_channel, private_channel, mpim, im\")\n",
    "        return response[\"channels\"]\n",
    "\n",
    "    def get_channel_by_name(self, channel_name):\n",
    "        for channel in self.list_channels():\n",
    "            if channel['name'] == channel_name:\n",
    "                return channel['id']\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32c0c1-5465-4ecf-9de3-07e662a77544",
   "metadata": {},
   "source": [
    "We need a Slack API Token for a custom app. You can create one [here](https://api.slack.com/apps/). Select `Create New App`->`\n",
    "From scratch` and provide an app name and a workspace where you develop the app. This needs to be a personal Slack workspace as you don't have permissions to create apps in IBM Slack workspaces.\n",
    "\n",
    "Now set up a bot token for your app in your workspace. In the navigation pane to the left select `Features`->`OAuth & Permissions`. Scroll down to section `Scopes` and add scopes for `app_mentions:read`, `channels:history`, `channels:read`, `groups:history`, `groups:read`,  `im:read`, `mpim:read` and `users:read`.\n",
    "Now scroll up to section `OAuth Tokens for Your Workspace` and click `Install to Workspace`. Now select your workspace where the app should be deployed (again note: You can't deploy to IBM Slack workspaces yourselfes. This requires an IBM Slack admin). Slack generates a new `Bot User OAuth Token` as part of this workspace deployment. Copy this token. You need it to run the below logic.\n",
    "\n",
    "You now need to add the new app to the channel(s) for which you want to retrieve the conversations. To do so, go to your Slack client, open the channel you want to use and type `@<your app name>` and press enter. Slack opens a dialog asking you whether you want to `Add to channel`. Click this option to add the app bot to your channel. \n",
    "\n",
    "You are now set up to proceed with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf1f83-b162-41b9-b502-7d70646676e7",
   "metadata": {},
   "source": [
    "Set the Slack API Token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4beaab-7c53-44ff-b252-46ca34c8ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slack_api_token = os.environ[\"SLACK_API_TOKEN\"]\n",
    "except KeyError:\n",
    "    slack_api_token = getpass.getpass(\"Please enter your Slack API Token (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a44044-1bf6-4da3-9da8-5ae173988a44",
   "metadata": {},
   "source": [
    "Initialize our Slack helper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608331f6-af25-4a43-9ada-f47174a905a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack = SlackHelper(slack_api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54234cbe-23df-4933-bda6-4ce21d476dc7",
   "metadata": {},
   "source": [
    "Set the slack channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a59ce88-df6a-4e2d-8768-1749756b22db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your slack channel is #vector-test with channel ID C062WE3UXS7.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    slack_channel_name = os.environ[\"SLACK_CHANNEL\"]\n",
    "except KeyError:\n",
    "    slack_channel_name = input(\"Please enter the name of your Slack channel to work with (hit enter): \")\n",
    "\n",
    "slack_channel = slack.get_channel_by_name(slack_channel_name)\n",
    "if not slack_channel:\n",
    "    raise BaseException(\"Channel #\" + slack_channel_name + \" does not exist\")\n",
    "print(\"Your slack channel is #\" + slack_channel_name + \" with channel ID \" + slack_channel + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01913012-3f84-4927-8f16-1bebe3ff3080",
   "metadata": {},
   "source": [
    "Retrieve the full conversation history of the selected channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19bb39b0-59c2-4c2d-8590-0d2e85dfdee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023-10-26 08:42:00, user=torsten): <@U05S5PHRU7J> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Michael Behrendt): <@U05RALRP84W> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Volkmar): <@U05RHA6C4US> has joined the channel\n",
      "(2023-10-26 08:43:30, user=torsten): I have a large tree in my garden that I need to get rid of. Any suggestions?\n",
      "      (2023-10-26 08:43:30, user=torsten): Hmm, how large is it?\n",
      "      (2023-10-26 08:43:30, user=torsten): Probably 10 meters.\n",
      "      (2023-10-26 08:43:30, user=torsten): Oh, this is a large tree indeed. Do you own a chainsaw?\n",
      "      (2023-10-26 08:43:30, user=torsten): Yes, I got one.\n",
      "      (2023-10-26 08:43:30, user=torsten): Well, you could theoretically cut it with your chainsaw. But that requires some skills. It can be dangerous for such a large tree.\n",
      "      (2023-10-26 08:43:30, user=torsten): I would recommend that you better hire an expert to get rid of the tree for you.\n",
      "      (2023-10-26 08:43:30, user=torsten): OK, thank you for the advise.\n",
      "(2023-10-26 08:49:17, user=Torsten): <@U05S5QZF6TA> has joined the channel\n",
      "(2023-10-26 11:20:33, user=torsten): I never manage to get my eggs cooked to the right point.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh boy. What's the problem? Are they too soft or too hard?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it happens both. Sometimes they are too soft, and another time when I cook them for exactly the same amount of time they are too hard.\n",
      "      (2023-10-26 11:20:33, user=torsten): Hmm, did you pay attention to the size of the eggs?\n",
      "      (2023-10-26 11:20:33, user=torsten): What? Why should I do that?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, larger eggs need longer time to become hard than smaller eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow! I did not know that. Stupid me! Thank you very much for this information. That explains everything! I need to adjust the cooking time depending on the size of the eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): And don't overcook them. Then the egg yolk turns green.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh yes, I see that sometimes and wonder why that happens.\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it is the sulfur in the yolk that reacts with the iron in there when it is cooked too long.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow, you know so much about eggs! Are you a bird?\n",
      "      (2023-10-26 11:20:33, user=torsten): Yes, I am.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slack_conversation = slack.get_messages_from_channel(slack_channel)\n",
    "print(slack_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb564f0d-0c26-40dc-9bcb-6810b9d45d0b",
   "metadata": {},
   "source": [
    "List all channels for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb501d61-fb93-41bb-95f9-5696aca7291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#random(id: C05RGLSNBFV)\n",
      "#foo(id: C05RK7JB336)\n",
      "#general(id: C05RVD0B141)\n",
      "#vector-test(id: C062WE3UXS7)\n"
     ]
    }
   ],
   "source": [
    "for channel in slack.list_channels():\n",
    "    if \"name\" in channel:\n",
    "        print(\"#\" + channel[\"name\"] + \"(id: \" + channel[\"id\"] + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680c1b6-14d4-493c-bddf-746adf0e94f0",
   "metadata": {},
   "source": [
    "## Prepare and Chunk the Slack Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b6d601-133f-4921-bac6-666f1f581fa8",
   "metadata": {},
   "source": [
    "We use LangChain as the framework to run the remainder parts of this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0634e17-d7f4-4ef1-a74c-be73c3c96d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain --upgrade | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d0f50f-c263-4670-8b4c-43649d029747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1100,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "\n",
    "slack_conversations = text_splitter.create_documents([slack_conversation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "701c548e-75d9-4576-aacb-dc214655510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========> Chunk 0\n",
      "(2023-10-26 08:42:00, user=torsten): <@U05S5PHRU7J> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Michael Behrendt): <@U05RALRP84W> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Volkmar): <@U05RHA6C4US> has joined the channel\n",
      "(2023-10-26 08:43:30, user=torsten): I have a large tree in my garden that I need to get rid of. Any suggestions?\n",
      "      (2023-10-26 08:43:30, user=torsten): Hmm, how large is it?\n",
      "      (2023-10-26 08:43:30, user=torsten): Probably 10 meters.\n",
      "      (2023-10-26 08:43:30, user=torsten): Oh, this is a large tree indeed. Do you own a chainsaw?\n",
      "      (2023-10-26 08:43:30, user=torsten): Yes, I got one.\n",
      "      (2023-10-26 08:43:30, user=torsten): Well, you could theoretically cut it with your chainsaw. But that requires some skills. It can be dangerous for such a large tree.\n",
      "      (2023-10-26 08:43:30, user=torsten): I would recommend that you better hire an expert to get rid of the tree for you.\n",
      "      (2023-10-26 08:43:30, user=torsten): OK, thank you for the advise.\n",
      "(2023-10-26 08:49:17, user=Torsten): <@U05S5QZF6TA> has joined the channel\n",
      "==========> Chunk 1\n",
      "(2023-10-26 08:49:17, user=Torsten): <@U05S5QZF6TA> has joined the channel\n",
      "(2023-10-26 11:20:33, user=torsten): I never manage to get my eggs cooked to the right point.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh boy. What's the problem? Are they too soft or too hard?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it happens both. Sometimes they are too soft, and another time when I cook them for exactly the same amount of time they are too hard.\n",
      "      (2023-10-26 11:20:33, user=torsten): Hmm, did you pay attention to the size of the eggs?\n",
      "      (2023-10-26 11:20:33, user=torsten): What? Why should I do that?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, larger eggs need longer time to become hard than smaller eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow! I did not know that. Stupid me! Thank you very much for this information. That explains everything! I need to adjust the cooking time depending on the size of the eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): And don't overcook them. Then the egg yolk turns green.\n",
      "==========> Chunk 2\n",
      "(2023-10-26 11:20:33, user=torsten): And don't overcook them. Then the egg yolk turns green.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh yes, I see that sometimes and wonder why that happens.\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it is the sulfur in the yolk that reacts with the iron in there when it is cooked too long.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow, you know so much about eggs! Are you a bird?\n",
      "      (2023-10-26 11:20:33, user=torsten): Yes, I am.\n"
     ]
    }
   ],
   "source": [
    "for idx, conversation in enumerate(slack_conversations):\n",
    "    print(\"==========> Chunk \" + str(idx))\n",
    "    print(conversation.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f150f-2750-4e0a-95d7-714412ed40ae",
   "metadata": {},
   "source": [
    "## Configure AI model for Computation of Vector Embeddings for our Slack Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83778652-2f6e-45eb-91c1-5465e95ecf4d",
   "metadata": {},
   "source": [
    "We use an embedding model from HuggingFace that we load and run in local runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb9e735-5c00-4f2c-a330-712489162868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33412c8c-dd5c-4fc0-b056-aa7f5a5ab6d1",
   "metadata": {},
   "source": [
    "Test embeddings computation with a sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "435a20d7-150f-443e-969c-adab95ef7982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03261888 -0.04178722  0.03815975 ...  0.04368008  0.0326837\n",
      "  0.03922174]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=0)\n",
    "query_result = embeddings.embed_query(\"Hello Embedding!\")\n",
    "print(np.array(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50dbb6-85f6-4871-beae-56ba31712cf4",
   "metadata": {},
   "source": [
    "## Upload Embeddings to a Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3262e-5496-43b7-95d8-da8a29ef9df3",
   "metadata": {},
   "source": [
    "We use <a href=\"https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-getting-started\" target=\"_blank\" rel=\"noopener no referrer\">IBM Cloud® Databases for Elasticsearch.</a> as vector database.\n",
    "\n",
    "The following cell retrieves the Elasticsearch users, password, host and port from the environment if available and prompts you otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfddc69a-d572-4303-9d30-8fe720f2912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch --upgrade | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b44ae0-51a9-4940-a6bf-8c36624adc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    esuser = os.environ[\"ESUSER\"]\n",
    "except KeyError:\n",
    "    esuser = input(\"Please enter your Elasticsearch user name (hit enter): \")\n",
    "try:\n",
    "    espassword = os.environ[\"ESPASSWORD\"]\n",
    "except KeyError:\n",
    "    espassword = getpass.getpass(\"Please enter your Elasticsearch password (hit enter): \")\n",
    "try:\n",
    "    eshost = os.environ[\"ESHOST\"]\n",
    "except KeyError:\n",
    "    eshost = input(\"Please enter your Elasticsearch hostname (hit enter): \")\n",
    "try:\n",
    "    esport = os.environ[\"ESPORT\"]\n",
    "except KeyError:\n",
    "    esport = input(\"Please enter your Elasticsearch port number (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2392b8-188f-4b63-9120-7a45b061cc65",
   "metadata": {},
   "source": [
    "By default Elasticsearch will start with security features like authentication and TLS enabled. To connect to the Elasticsearch cluster you’ll need to configure the Python Elasticsearch client to use HTTPS with the generated CA certificate in order to make requests successfully. Details can be found <a href=\"https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new\" target=\"_blank\" rel=\"noopener no referrer\">here</a>. In this notebook certificate fingerprints will be used for authentication. \n",
    "\n",
    "**Verifying HTTPS with certificate fingerprints (Python 3.10 or later)** If you don’t have access to the generated CA file from Elasticsearch you can use the following script to output the root CA fingerprint of the Elasticsearch instance with openssl s_client <a href=\"https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#_verifying_https_with_certificate_fingerprints_python_3_10_or_later\" target=\"_blank\" rel=\"noopener no referrer\"> (docs)</a>:\n",
    "\n",
    "The following cell retrieves the fingerprint information using a shell command and stores it in variable `ssl_assert_fingerprint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b23663ff-6e99-424b-9413-46cafbde8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "es_ssl_fingerprint = !openssl s_client -connect $ESHOST:$ESPORT -showcerts </dev/null 2>/dev/null | openssl x509 -fingerprint -sha256 -noout -in /dev/stdin\n",
    "es_ssl_fingerprint = es_ssl_fingerprint[0].lstrip(\"SHA256 Fingerprint=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b58d545-50ad-4fde-8a12-0555dfc3a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "es_index=\"slack_index\"\n",
    "\n",
    "es_connection = Elasticsearch([f\"https://{esuser}:{espassword}@{eshost}:{esport}\"],\n",
    "                              basic_auth=(esuser, espassword),\n",
    "                              request_timeout=None,\n",
    "                              ssl_assert_fingerprint=es_ssl_fingerprint)\n",
    "\n",
    "knowledge_base = ElasticsearchStore(es_connection=es_connection,\n",
    "                                    index_name=es_index,\n",
    "                                    embedding=embeddings,\n",
    "                                    strategy=ElasticsearchStore.ApproxRetrievalStrategy(),\n",
    "                                    distance_strategy=\"DOT_PRODUCT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fa1a6-6482-41dd-b63a-4f276f17303b",
   "metadata": {},
   "source": [
    "The `add_texts()` function of the ElasticsearchStore wrapper in LangChain is a compound function that prepares the document data, computes the embeddings using the HuggingFace embedding model and then loads everything to Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e2bb2d6-92e7-49b5-abd7-c0fb84d45df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if es_connection.indices.exists(index=es_index):\n",
    "    es_connection.indices.delete(index=es_index)\n",
    "_ = knowledge_base.add_texts(texts=[chunk.page_content for chunk in slack_conversations],\n",
    "                             metadatas=[{'title': \"Chunk-\"+str(idx), 'id': idx}\n",
    "                                for idx, chunk in enumerate(slack_conversations)],\n",
    "                             index_name=es_index,\n",
    "                             ids=[str(idx) for idx, chunk in enumerate(slack_conversations)]  # unique for each doc\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac436eba-86c5-42fe-b6a0-67a87801c7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'metadata': {'properties': {'id': {'type': 'long'},\n",
       "    'title': {'type': 'text',\n",
       "     'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}},\n",
       "  'text': {'type': 'text',\n",
       "   'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}},\n",
       "  'vector': {'type': 'dense_vector',\n",
       "   'dims': 384,\n",
       "   'index': True,\n",
       "   'similarity': 'dot_product'}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(es_connection.indices.get(index=es_index))[\"slack_index\"][\"mappings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8bc3db4-01d4-47e5-bb91-50aa216f436c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_connection.count(index=es_index)[\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfebf9-17c7-4612-9f54-3ddaaa0e4972",
   "metadata": {},
   "source": [
    "For testing we run a few simple vector similarity searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ee66100-1b56-486e-8402-a2e28dbd3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for similar_document in knowledge_base.similarity_search_with_score(\"Do you know anything about card games?\", k=10):\n",
    "    if similar_document[1] > 0.59:\n",
    "        print(\"Similarity: \" + str(similar_document[1]))\n",
    "        print(similar_document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89c71e2e-d13c-44a0-a010-db0735aceda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6478079\n",
      "(2023-10-26 08:49:17, user=Torsten): <@U05S5QZF6TA> has joined the channel\n",
      "(2023-10-26 11:20:33, user=torsten): I never manage to get my eggs cooked to the right point.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh boy. What's the problem? Are they too soft or too hard?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it happens both. Sometimes they are too soft, and another time when I cook them for exactly the same amount of time they are too hard.\n",
      "      (2023-10-26 11:20:33, user=torsten): Hmm, did you pay attention to the size of the eggs?\n",
      "      (2023-10-26 11:20:33, user=torsten): What? Why should I do that?\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, larger eggs need longer time to become hard than smaller eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow! I did not know that. Stupid me! Thank you very much for this information. That explains everything! I need to adjust the cooking time depending on the size of the eggs.\n",
      "      (2023-10-26 11:20:33, user=torsten): And don't overcook them. Then the egg yolk turns green.\n",
      "Similarity: 0.5976906\n",
      "(2023-10-26 11:20:33, user=torsten): And don't overcook them. Then the egg yolk turns green.\n",
      "      (2023-10-26 11:20:33, user=torsten): Oh yes, I see that sometimes and wonder why that happens.\n",
      "      (2023-10-26 11:20:33, user=torsten): Well, it is the sulfur in the yolk that reacts with the iron in there when it is cooked too long.\n",
      "      (2023-10-26 11:20:33, user=torsten): Wow, you know so much about eggs! Are you a bird?\n",
      "      (2023-10-26 11:20:33, user=torsten): Yes, I am.\n"
     ]
    }
   ],
   "source": [
    "for similar_document in knowledge_base.similarity_search_with_score(\"Any cooking best practices?\", k=10):\n",
    "    if similar_document[1] > 0.56:\n",
    "        print(\"Similarity: \" + str(similar_document[1]))\n",
    "        print(similar_document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1cc4267-da32-44e4-81d4-b47102f51452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6981352\n",
      "(2023-10-26 08:42:00, user=torsten): <@U05S5PHRU7J> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Michael Behrendt): <@U05RALRP84W> has joined the channel\n",
      "(2023-10-26 08:42:08, user=Volkmar): <@U05RHA6C4US> has joined the channel\n",
      "(2023-10-26 08:43:30, user=torsten): I have a large tree in my garden that I need to get rid of. Any suggestions?\n",
      "      (2023-10-26 08:43:30, user=torsten): Hmm, how large is it?\n",
      "      (2023-10-26 08:43:30, user=torsten): Probably 10 meters.\n",
      "      (2023-10-26 08:43:30, user=torsten): Oh, this is a large tree indeed. Do you own a chainsaw?\n",
      "      (2023-10-26 08:43:30, user=torsten): Yes, I got one.\n",
      "      (2023-10-26 08:43:30, user=torsten): Well, you could theoretically cut it with your chainsaw. But that requires some skills. It can be dangerous for such a large tree.\n",
      "      (2023-10-26 08:43:30, user=torsten): I would recommend that you better hire an expert to get rid of the tree for you.\n",
      "      (2023-10-26 08:43:30, user=torsten): OK, thank you for the advise.\n",
      "(2023-10-26 08:49:17, user=Torsten): <@U05S5QZF6TA> has joined the channel\n"
     ]
    }
   ],
   "source": [
    "for similar_document in knowledge_base.similarity_search_with_score(\"Do you know anything about trees?\", k=5):\n",
    "    if similar_document[1] > 0.59:\n",
    "        print(\"Similarity: \" + str(similar_document[1]))\n",
    "        print(similar_document[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c1141-8e01-4d0f-ba7d-644fac90f7ff",
   "metadata": {},
   "source": [
    "## Configure Large Language Model for for the AI Generation with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bb86ea2-f0f7-4355-9b34-93b85ce10551",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    apikey = os.environ[\"IBM_CLOUD_API_KEY\"]\n",
    "except KeyError:\n",
    "    apikey = getpass.getpass(\"Please enter your WML api key (hit enter): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dba77160-cff0-4f99-a233-312583a524d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": apikey\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e943af-bb03-4017-bbf8-7c94e7ad5c84",
   "metadata": {},
   "source": [
    "The API requires a WatsonX project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n",
    "\n",
    "**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74be811b-e987-4df1-b532-d5bbb4bc9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e80a853c-cc58-4aab-a91a-492a6f217786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "model_id = ModelTypes.FLAN_T5_XXL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3026c54-8dde-4f3f-86f0-846dbf24ef7a",
   "metadata": {},
   "source": [
    "Set model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "241ec3c9-cae8-4985-bcf1-7d58f47b1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a016027-49fd-436f-bb63-97681299dc55",
   "metadata": {},
   "source": [
    "Initialize the Model in WatsonX.ai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4aeea2e-6c57-42ec-9b14-2abd31fc19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "llm = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ").to_langchain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b52bea-9868-42d2-902c-cdd1f58e4969",
   "metadata": {},
   "source": [
    "## Prompting an LLM with a Retrieval Augmentation using the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc6e19-1c3f-4e3c-986e-71b70508172c",
   "metadata": {},
   "source": [
    "We use the WatsonX large language model to built a Question-Answer prompt chain and we use the vector database that we prepared above as knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81f25579-5cf4-4b3f-b460-a916f905cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
    "                                 retriever=knowledge_base.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af66bdb7-9f92-46ec-be3d-928f816552e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut a tree.\n"
     ]
    }
   ],
   "source": [
    "print(qa({\"query\": \"What can I do with a chainsaw?\"})[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67ace606-f21c-4c0a-b568-e0d477a01553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hire an expert to get rid of the tree for you.\n"
     ]
    }
   ],
   "source": [
    "print(qa({\"query\": \"What is the best method to get rid of a 12 meter high tree?\"})[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "007641d0-bbbc-47aa-9b6f-d0ad23e8cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjust the cooking time depending on the size of the eggs.\n"
     ]
    }
   ],
   "source": [
    "print(qa({\"query\": \"How can I cook eggs to the point?\"})[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7f5a59d-8328-4555-81be-de08697621f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"query\": \"What is a good card game?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed8352-5443-4466-ab56-02fca1a9f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
